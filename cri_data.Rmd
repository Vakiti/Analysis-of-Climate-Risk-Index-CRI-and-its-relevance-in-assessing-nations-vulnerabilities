---
title: "cri_data"
author: "Shanya Chaubey"
date: "2023-03-11"
output: html_document
---


```{r setup, include=FALSE, echo = TRUE}
knitr::opts_knit$set(root.dir = 'C:\\Users\\chaub\\Documents\\CU_Boulder\\Spring 2023\\STAT 5000\\CRI_analysis')
```

```{r}

library(tidyverse)
library(dplyr)
library(tidyr)
library(compare)
library(Hmisc)
library(corrplot)
library(moments)


```


```{r}
data <- read_csv('climate-risk-index-1.csv')
head(data)
columns <- as.list(colnames(data))
columns

```

```{r}
data <- data %>% select(-c('cartodb_id','the_geom', 'the_geom_webmercator', 'rw_country_name'))
head(data)

names(data)[names(data) == 'rw_country_code'] <- 'country_code'

head(data)
```

```{r}

pop_density <-  read_csv('population_density.csv')
head(pop_density)

#unit = people per sq. km of land area
pop_density <- pop_density %>% select(c('Country Code','2019 [YR2019]'))
head(pop_density)

pop_density$`2019 [YR2019]` <- as.numeric(pop_density$`2019 [YR2019]`)
head(pop_density)

colnames(pop_density)<- c('country_code', 'pop_den')

new_pop_den <- pop_density %>% distinct()


#change column name of Country Code  to country_code

```

```{r}
gdp_p_c <- read_csv('gdp_per_capita.csv')
head(gdp_p_c)

#unit-current US$
gdp_p_c <- gdp_p_c%>% select(c('Country Code', '2019 [YR2019]'))
head(gdp_p_c)

gdp_p_c$`2019 [YR2019]` <- as.numeric(gdp_p_c$`2019 [YR2019]`)
head(gdp_p_c)
#change column name of Country Code  to country_code

colnames(gdp_p_c) <- c('country_code', 'GDP_per_capita')
head(gdp_p_c)
```





```{r}
epi_2020 <- read_csv('2020_epi.csv')
head(epi_2020)


epi_score_2020<- epi_2020 %>% select(c( 'iso', 'EPI.new'))
head(epi_score_2020)


epi_2018 <- read_csv('2018_epi.csv')
head(epi_2018)


epi_score_2018<- epi_2018 %>% select(c( 'iso', 'EPI.current'))
head(epi_score_2018)


epi_2019 <- inner_join(epi_score_2018, epi_score_2020, by= "iso")
head(epi_2019)

print('Missing value in dataframe:')
sum(is.na(epi_2019))

epi_2019 <- epi_2019  %>% mutate(EPI_new = (EPI.current+EPI.new)/2) %>% select(c('iso', 'EPI_new'))
head(epi_2019)

colnames(epi_2019) <- c('country_code', 'EPI_score')
head(epi_2019)

```


```{r}

data_1 <- inner_join(data, pop_density, by = 'country_code')
data_2 <- inner_join(data_1, gdp_p_c, by = 'country_code')
data_3 <- inner_join(data_2, epi_2019, by = 'country_code', )
head(data_3)

data_3 <- data_3 %>% select(-c('fatalities_per_100k_rank', 'fatalities_rank', 'losses_per_gdp__rank', 'losses_usdm_ppp_rank'))

head(data_3)

```

## Checking for missing values

```{r}
sum(is.na(data_3))

summary(data_3)



```

##Checking distribution of each variable

```{r}
#p_1 <- hist(data_3$EPI_score, main = 'Distribution of EPI score', xlab = 'EPI score')
#p_1



data_num <- select_if(data_3, is.numeric)
num_cols <- colnames(data_num)
print(num_cols)



for (i in num_cols){
  print(i)
  m <- paste('Distribution of', i)
  print(m)
  x <- i
  print(x)
  data <- data_num[,i]
  
  print(class(data))
  (hist(data, main=m, xlab = x)) #figure out why the graph heading is not showing up on hist
}

```

##Checking correlation

Lower cri index indicates higher risk for the country, but it should be kept in mind that the data provided by the countries might not be complete or accurate.

```{r}

corr_dat <- cor(data_num)
corrplot.mixed(corr_dat, upper = 'square', lower = 'number', addgrid.col = 'black', tl.col = 'black')


```

##Checking the central tendencies of numerical columns


```{r}

data_to_use <- data_num %>% select(-index)
#print(colnames(data_to_use))
find_mode <- function(x) {
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}

# loop through each column of the dataframe and find the central tendencies
for (col in names(data_to_use)) {
  if (is.numeric(data_to_use[[col]])) {
    mean_val <- mean(data_to_use[[col]])
    median_val <- median(data_to_use[[col]])
    mode_val <- find_mode(data_to_use[[col]])
    cat("The mean of ", col, " is ", mean_val, ", median of ", col, " is ", median_val, ", and mode of ", col, " is ", mode_val, ".\n\n", sep="")
  }
}


```

##Checking for dispersion of data

```{r}

for (col in names(data_to_use)) {
  if (is.numeric(data_to_use[[col]])) {
    # calculate range and IQR
    range_val <- max(data_to_use[[col]]) - min(data_to_use[[col]])
    IQR_val <- diff(quantile(data_to_use[[col]], c(0.25, 0.75), na.rm = TRUE))
    
    # calculate the number of outliers
    outliers <- data_to_use[[col]] < quantile(data_to_use[[col]], 0.25, na.rm = TRUE) - 1.5 * IQR_val | data_to_use[[col]] > quantile(data_to_use[[col]], 0.75, na.rm = TRUE) + 1.5 * IQR_val
    num_outliers <- sum(outliers)
    
    # print the results
    cat("The range of the '", col, "' column is ", range_val, ", the IQR of the '", col, "' column is ", IQR_val, ", and the number of outliers in the '", col, "' column are ", num_outliers, ".\n\n", sep="")
  }
}

```
```{r}
# create an empty data frame to store the results
results <- data.frame(column = character(), range = numeric(), IQR = numeric(), num_outliers = numeric(), stringsAsFactors = FALSE)

# loop through each column of the dataframe and calculate range, IQR and number of outliers
for (col in names(data_to_use)) {
  if (is.numeric(data_to_use[[col]])) {
    # calculate range and IQR
    range_val <- max(data_to_use[[col]], na.rm = TRUE) - min(data_to_use[[col]], na.rm = TRUE)
    IQR_val <- diff(quantile(data_to_use[[col]], c(0.25, 0.75), na.rm=TRUE))
    
    # calculate the number of outliers
    outliers <- data_to_use[[col]] < quantile(data_to_use[[col]], 0.25, na.rm=TRUE) - 1.5 * IQR_val | data_to_use[[col]] > quantile(data_to_use[[col]], 0.75, na.rm=TRUE) + 1.5 * IQR_val
    num_outliers <- sum(outliers, na.rm=TRUE)
    
    # add the results to the data frame
    results <- rbind(results, data.frame(column = col, range = range_val, IQR = IQR_val, num_outliers = num_outliers, stringsAsFactors = FALSE))
  }
}

# print the results as a formatted table
summary_table <- knitr::kable(results, caption = "Summary of Numeric Columns in data", row.names = FALSE, col.names = c('Column', 'Range', 'IQR', 'No. of Outliers'))
summary_table

```
#Checking the standard deviation and variance of each column

```{r}
# calculate the standard deviation and variance for each numeric variable
sds <- sapply(data_to_use, sd, na.rm = TRUE)
vars <- sapply(data_to_use, var, na.rm = TRUE)

# print the results
for (i in 1:length(sds)) {
  print(paste("Standard deviation and variance of", colnames(data_to_use)[i], "is", sds[i], "and", vars[i]))
 
}

```
#Checking skewness and kurtosis of variables

```{r}

skew <- sapply(data_to_use, skewness, na.rm = TRUE)
kurt <- sapply(data_to_use, kurtosis, na.rm = TRUE)

for (i in 1:length(skew)){
  print(paste("The skewness and kurtosis of", colnames(data_to_use)[i], "is", skew[i], "and", kurt[i]))
}


```
#Mapping continents to each country

```{r}

key <- read.csv("country-and-continent-codes-list-csv.csv")

key <- key %>% select(c('Continent_Name', 'Three_Letter_Country_Code'))
colnames(key) <- c("new", "old")
head(key)

head(key)
#key$old
for (i in 1: length(data_3$cri_rank)){
  if (data_3$country_code[i] %in% key$old){
    j <- grep(data_3$country_code[i],key$old)
    data_3$continent[i] <- key$new[j]
  }
}

```

#Checking the distribution of cri rank over continents

```{r}
install.packages("maps")
install.packages("mapdata")
install.packages("viridis")
library(ggplot2)
library(maps)
library(mapdata)
library(viridis)

# Load world map data
world <- map_data("world")

# Aggregate cri_score by country
#cri_country <- aggregate(cri_score ~ country_code, data_3, FUN = mean())

# Merge cri_country with world map data
cri_map <- merge(world, data_3, by.x = "region", by.y = "country")

# Create heatmap with cri_score
ggplot(cri_map, aes(x = long, y = lat, group = region, fill = cri_score)) +
  geom_tile() +
  scale_fill_viridis(name = "CRI Score", option = "A", na.value = "gray90") +
  labs(title = "CRI Score Distribution by Country") +
  theme_void()
```



```{r}
data_scale <- scale(data_to_use)
print(colnames(data_scale))

find_mode <- function(x) {
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}

# loop through each column of the dataframe and find the central tendencies
for (col in names(data_scale)) {
  if (is.numeric(data_scale[[col]])) {
    mean_val <- mean(data_scale[[col]])
    median_val <- median(data_scale[[col]])
    mode_val <- find_mode(data_scale[[col]])
    cat("The mean of ", col, " is ", mean_val, ", median of ", col, " is ", median_val, ", and mode of ", col, " is ", mode_val, ".\n\n", sep="")
  }
}

```

#Clustering countries absed on geographic and economic data

```{r}
library(cluster)
library(factoextra)
library(stats)
library(NbClust)

```

























